{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Academic Conntect\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import TFAutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student GUID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Research Interests</th>\n",
       "      <th>University Field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1c5fc27-048a-4fad-b32a-57b6613f5c6d</td>\n",
       "      <td>Daniel Cain</td>\n",
       "      <td>Photonics, Cosmology, Theoretical Physics, Exp...</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ead3d7a5-bddc-4ad1-ab55-4db006731802</td>\n",
       "      <td>Amy Potter</td>\n",
       "      <td>Cognitive Psychology, Developmental Psychology...</td>\n",
       "      <td>Psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c6f1e6d1-21fe-4daa-a022-ff9e0f4fd957</td>\n",
       "      <td>Jessica Collins</td>\n",
       "      <td>Materials Science, Physical Chemistry, Inorgan...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3e19f76f-46b4-46c4-a489-36053fd8d79e</td>\n",
       "      <td>Maria Singh</td>\n",
       "      <td>Economic History, History of Science, Military...</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31bbb063-8dae-4e81-97c4-456e8df9af33</td>\n",
       "      <td>James Thomas</td>\n",
       "      <td>Geometry, Mathematical Physics, Statistics, Al...</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Student GUID             Name  \\\n",
       "0  c1c5fc27-048a-4fad-b32a-57b6613f5c6d      Daniel Cain   \n",
       "1  ead3d7a5-bddc-4ad1-ab55-4db006731802       Amy Potter   \n",
       "2  c6f1e6d1-21fe-4daa-a022-ff9e0f4fd957  Jessica Collins   \n",
       "3  3e19f76f-46b4-46c4-a489-36053fd8d79e      Maria Singh   \n",
       "4  31bbb063-8dae-4e81-97c4-456e8df9af33     James Thomas   \n",
       "\n",
       "                                  Research Interests University Field  \n",
       "0  Photonics, Cosmology, Theoretical Physics, Exp...          Physics  \n",
       "1  Cognitive Psychology, Developmental Psychology...       Psychology  \n",
       "2  Materials Science, Physical Chemistry, Inorgan...        Chemistry  \n",
       "3  Economic History, History of Science, Military...          History  \n",
       "4  Geometry, Mathematical Physics, Statistics, Al...      Mathematics  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read university dataset \n",
    "uni_data = pd.read_excel(\"university_data.xlsx\")\n",
    "uni_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cleaning up Research Interests feature\n",
    "uni_data['Research Interests'] = uni_data['Research Interests'].str.lower().str.replace(r'[^\\w\\s]+', '')\n",
    "\n",
    "# Cleaning up \"University Field\" feature\n",
    "# uni_data[\"University Field\"] = uni_data[\"University Field\"].str.lower().str.replace(r'[^\\w\\s]+', '')\n",
    "# uni_data.head()\n",
    "encoder = LabelEncoder()\n",
    "uni_data['University Field'] = encoder.fit_transform(uni_data['University Field'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFAutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def embed_text(texts):\n",
    "    inputs = tokenizer(texts.tolist(), padding=True, truncation=True, max_length=512, return_tensors=\"tf\")\n",
    "    outputs = model(inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "# Embed 'Research Interests'\n",
    "embeddings = embed_text(uni_data['Research Interests'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35122058,  0.2672667 , -0.17760639, ..., -0.17172086,\n",
       "        -0.18274336,  0.6307969 ],\n",
       "       [ 0.13852608,  0.29572952, -0.7052915 , ..., -0.30475768,\n",
       "        -0.17106837,  0.39814553],\n",
       "       [ 0.34270325,  0.21112193, -0.3461482 , ..., -0.23749661,\n",
       "        -0.01269638,  0.6580549 ],\n",
       "       ...,\n",
       "       [-0.03102134, -0.03761458, -0.58762026, ..., -0.3957855 ,\n",
       "        -0.20575732,  0.42250288],\n",
       "       [ 0.49557954,  0.16372317, -0.3434162 , ..., -0.19094762,\n",
       "         0.10214731,  0.82497257],\n",
       "       [ 0.49353784,  0.18878661, -0.33193555, ..., -0.21652126,\n",
       "        -0.00542787,  0.8533199 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale embeddings and the encoded field\n",
    "scaler = StandardScaler()\n",
    "embeddings_scaled = scaler.fit_transform(embeddings)\n",
    "field_scaled = scaler.fit_transform(uni_data[['University Field']])\n",
    "\n",
    "# Combine embeddings with the university field\n",
    "combined_features = np.hstack((embeddings_scaled, field_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(combined_features)\n",
    "\n",
    "# Optionally, create a DataFrame to view similarity scores\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=uni_data['Student GUID'], columns=uni_data['Student GUID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student GUID\n",
      "149b3317-e913-4008-bd23-7a2f445b6f0b    0.988040\n",
      "ac2087b4-ef74-4b5e-abad-5302f9d7e368    0.987624\n",
      "adb2fcac-7d96-47ec-8f89-29a6ec92b599    0.984967\n",
      "a70f1a6e-2bc8-4060-b3a4-f0c3045e769c    0.984064\n",
      "7aeaf1f2-d2a4-4176-abdf-96212da216d4    0.982235\n",
      "Name: c1c5fc27-048a-4fad-b32a-57b6613f5c6d, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_top_matches(student_name, similarity_df, top_n=5):\n",
    "    scores = similarity_df.loc[student_name]\n",
    "    top_matches = scores.sort_values(ascending=False)[1:top_n+1]  # exclude self-match\n",
    "    return top_matches\n",
    "\n",
    "# Example usage\n",
    "top_matches = get_top_matches('c1c5fc27-048a-4fad-b32a-57b6613f5c6d', similarity_df)\n",
    "print(top_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# max_len = 0\n",
    "# for i in uni_data[\"Research Interests\"]:\n",
    "#     if len(i.split()) > max_len:\n",
    "#         max_len = len(i.split())\n",
    "\n",
    "# print(max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import TextVectorization \n",
    "\n",
    "# # Use the default TextVectorization variables\n",
    "# text_vectorizer = TextVectorization(max_tokens=max_len, # how many words in the vocabulary (all of the different words in your text)\n",
    "#                                     standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "#                                     split=\"whitespace\", # how to split tokens\n",
    "#                                     ngrams=None, # create groups of n-words?\n",
    "#                                     output_mode=\"int\", # how to map tokens to numbers\n",
    "#                                     output_sequence_length=None,\n",
    "#                                     pad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_vocab_length = 10000\n",
    "\n",
    "# text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "#                                     output_mode=\"int\",\n",
    "#                                     output_sequence_length=max_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
